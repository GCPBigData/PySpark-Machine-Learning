{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Churn Prediction\n",
    "\n",
    "Here I quote this pyspark example from [this blog](https://mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages/). The following codes apply a decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disable warnings, set Matplotlib inline plotting and load Pandas package\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.mpl_style = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sqlContext\n",
    "CV_data = sqlContext.read.load('./data/churn-bigml-80.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')\n",
    "\n",
    "final_test_data = sqlContext.read.load('./data/churn-bigml-20.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')\n",
    "CV_data.cache()\n",
    "CV_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_data.take(5), columns=CV_data.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV_data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in CV_data.dtypes if t[1] == 'int' or t[1] == 'double']\n",
    "\n",
    "sampled_data = CV_data.select(numeric_features).sample(False, 0.10).toPandas()\n",
    "\n",
    "axs = pd.scatter_matrix(sampled_data, figsize=(12, 12));\n",
    "\n",
    "# Rotate axis labels and remove axis ticks\n",
    "n = len(sampled_data.columns)\n",
    "for i in range(n):\n",
    "    v = axs[i, 0]\n",
    "    v.yaxis.label.set_rotation(0)\n",
    "    v.yaxis.label.set_ha('right')\n",
    "    v.set_yticks(())\n",
    "    h = axs[n-1, i]\n",
    "    h.xaxis.label.set_rotation(90)\n",
    "    h.set_xticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "\n",
    "binary_map = {'Yes':1.0, 'No':0.0, 'True':1.0, 'False':0.0}\n",
    "toNum = UserDefinedFunction(lambda k: binary_map[k], DoubleType())\n",
    "\n",
    "CV_data = CV_data.drop('State').drop('Area code') \\\n",
    "    .drop('Total day charge').drop('Total eve charge') \\\n",
    "    .drop('Total night charge').drop('Total intl charge') \\\n",
    "    .withColumn('Churn', toNum(CV_data['Churn'])) \\\n",
    "    .withColumn('International plan', toNum(CV_data['International plan'])) \\\n",
    "    .withColumn('Voice mail plan', toNum(CV_data['Voice mail plan'])).cache()\n",
    "\n",
    "final_test_data = final_test_data.drop('State').drop('Area code') \\\n",
    "    .drop('Total day charge').drop('Total eve charge') \\\n",
    "    .drop('Total night charge').drop('Total intl charge') \\\n",
    "    .withColumn('Churn', toNum(final_test_data['Churn'])) \\\n",
    "    .withColumn('International plan', toNum(final_test_data['International plan'])) \\\n",
    "    .withColumn('Voice mail plan', toNum(final_test_data['Voice mail plan'])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_data.take(5), columns=CV_data.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "def labelData(data):\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[-1], row[:-1]))\n",
    "\n",
    "training_data, testing_data = labelData(CV_data).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n",
    "                                     categoricalFeaturesInfo={1:2, 2:2},\n",
    "                                     impurity='gini', maxBins=32)\n",
    "\n",
    "print model.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def getPredictionsLabels(model, test_data):\n",
    "    predictions = model.predict(test_data.map(lambda r: r.features))\n",
    "    return predictions.zip(test_data.map(lambda r: r.label))\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print 'Precision of True ', metrics.precision(1)\n",
    "    print 'Precision of False', metrics.precision(0)\n",
    "    print 'Recall of True    ', metrics.recall(1)\n",
    "    print 'Recall of False   ', metrics.recall(0)\n",
    "    print 'F-1 Score         ', metrics.fMeasure()\n",
    "    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV_data.groupby('Churn').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stratified_CV_data = CV_data.sampleBy('Churn', fractions={0: 388./2278, 1: 1.0}).cache()\n",
    "\n",
    "stratified_CV_data.groupby('Churn').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = labelData(stratified_CV_data).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n",
    "                                     categoricalFeaturesInfo={1:2, 2:2},\n",
    "                                     impurity='gini', maxBins=32)\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = labelData(stratified_CV_data).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n",
    "                                     categoricalFeaturesInfo={1:2, 2:2},\n",
    "                                     impurity='gini', maxBins=32)\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "printMetrics(predictions_and_labels)\n",
    "Precision of True  0.958333333333\n",
    "Precision of False 0.738636363636\n",
    "Recall of True     0.75\n",
    "Recall of False    0.955882352941\n",
    "F-1 Score          0.8375\n",
    "Confusion Matrix\n",
    "[[ 65\\.   3.]\n",
    " [ 23\\.  69.]]\n",
    "With these new recall values, we can see that the stratified data was helpful in building a less biased model, which will ultimately provide more generalized and robust predictions.\n",
    "\n",
    "Using the Spark ML Package¶\n",
    "The ML package is the newer library of machine learning routines. It provides an API for pipelining data transformers, estimators and model selectors. We'll use it here to perform cross-validation across several decision trees with various maxDepth parameters in order to find the optimal model.\n",
    "\n",
    "Pipelining¶\n",
    "The ML package needs data be put in a (label: Double, features: Vector) DataFrame format with correspondingly named fields. The vectorizeData() function below performs this formatting.\n",
    "\n",
    "Next we'll pass the data through a pipeline of two transformers, StringIndexer() and VectorIndexer() which index the label and features fields respectively. Indexing categorical features allows decision trees to treat categorical features appropriately, improving performance. The final element in our pipeline is an estimator (a decision tree classifier) training on the indexed labels and features.\n",
    "\n",
    "Model Selection¶\n",
    "Given the data set at hand, we would like to determine which parameter values of the decision tree produce the best model. We need a systematic approach to quantatively measure the performance of the models and ensure that the results are reliable. This task of model selection is often done using cross validation techniques. A common technique is k-fold cross validation, where the data is randomly split into k partitions. Each partition is used once as the testing data set, while the rest are used for training. Models are then generated using the training sets and evaluated with the testing sets, resulting in k model performance measurements. The average of the performance scores is often taken to be the overall score of the model, given its build parameters.\n",
    "\n",
    "For model selection we can search through the model parameters, comparing their cross validation performances. The model parameters leading to the highest performance metric produce the best model.\n",
    "\n",
    "The ML package supports k-fold cross validation, which can be readily coupled with a parameter grid builder and an evaluator to construct a model selection workflow. Below, we'll use a transformation/estimation pipeline to train our models. The cross validator will use the ParamGridBuilder to iterate through the maxDepth parameter of the decision tree and evaluate the models using the F1-score, repeating 3 times per parameter value for reliable results.\n",
    "\n",
    "In [14]:\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def vectorizeData(data):\n",
    "    return data.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n",
    "\n",
    "vectorized_CV_data = vectorizeData(stratified_CV_data)\n",
    "\n",
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label',\n",
    "                             outputCol='indexedLabel').fit(vectorized_CV_data)\n",
    "\n",
    "# Automatically identify categorical features and index them\n",
    "featureIndexer = VectorIndexer(inputCol='features',\n",
    "                               outputCol='indexedFeatures',\n",
    "                               maxCategories=2).fit(vectorized_CV_data)\n",
    "\n",
    "# Train a DecisionTree model\n",
    "dTree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dTree])\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid = ParamGridBuilder().addGrid(dTree.maxDepth, [2,3,4,5,6,7]).build()\n",
    "\n",
    "# Set F-1 score as evaluation metric for best model selection\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n",
    "                                              predictionCol='prediction', metricName='f1')    \n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "CV_model = crossval.fit(vectorized_CV_data)\n",
    "\n",
    "# Fetch best model\n",
    "tree_model = CV_model.bestModel.stages[2]\n",
    "print tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_46c0afd18278e35a40fd) of depth 5 with 53 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized_test_data = vectorizeData(final_test_data)\n",
    "\n",
    "transformed_data = CV_model.transform(vectorized_test_data)\n",
    "print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n",
    "\n",
    "predictions = transformed_data.select('indexedLabel', 'prediction', 'probability')\n",
    "predictions.toPandas().head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
